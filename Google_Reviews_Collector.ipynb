{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üåü Google Reviews Collector - Daily Scraper\n",
        "\n",
        "Fetches Google reviews for all locations and stores them in BigQuery.\n",
        "\n",
        "### Features:\n",
        "- ‚úÖ Historical mode: Get all reviews\n",
        "- ‚úÖ Incremental mode: Get reviews after specific date  \n",
        "- ‚úÖ Auto mode: Smart detection of last scraped date\n",
        "- ‚úÖ Perfect for daily/scheduled runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install packages\n",
        "!pip install -q requests pandas google-cloud-bigquery google-auth db-dtypes\n",
        "\n",
        "# Import libraries\n",
        "import json\n",
        "import http.client\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime, timezone\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud import bigquery\n",
        "from google.colab import userdata\n",
        "\n",
        "print(\"‚úÖ Setup complete\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configuration\n",
        "RAPIDAPI_HOST = \"google-search-master-mega.p.rapidapi.com\"\n",
        "RAPIDAPI_KEY = \"ac0025f410mshd0c260cb60f3db6p18c4b0jsnc9b7413cd574\"\n",
        "\n",
        "PROJECT_ID = \"shopper-reviews-477306\"\n",
        "DATASET_ID = \"shopper_reviews_db\"\n",
        "SOURCE_TABLE = \"Map_location\"\n",
        "REVIEWS_TABLE = \"Reviews\"\n",
        "\n",
        "BIGQUERY_CREDENTIALS = {\n",
        "    \"type\": \"service_account\",\n",
        "    \"project_id\": \"shopper-reviews-477306\",\n",
        "    \"private_key_id\": \"679b00310997262ff77901f080075b509eb9c770\",\n",
        "    \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCPrVXmepJWx8A8\\nXLqDARbLqqmgPwQ4NEmCCOmAZ019aFToc0Yho0/hDyMhRhsW6z/5h8YVEbheb2oR\\nmFK6/v3UEN1Mf6oJWag9pBngM6IO96QAzozjXjCmIVYJku1HWi+7b4mX7La8p77N\\n5fJdOh30ceC6cJSDA51r2xGJDmchRPNhRR8CS9u3xAeZZeB/pgShwJcLM4WY4L3P\\niwc7qkQb91NPbB2/p3hL/JJAtCvVKf61xlWGOKEGW3pIwBUUcF2/OJ3FTuWrY7P8\\n1c/Kz9LUYOZpztK9zjFCNcnCQvvVAow9bqg3fw6xqE172dQT1FG6AieFSCyUib5B\\nXxwNu0phAgMBAAECggEAET1ThPqIxqA54RmgnjQqP7k0Q0XBxDCvRUq7zIFuBdyC\\nm6Wr8OtUnAT3Snh2qv2tSSFRKO6zDaRsDhJrPYQigX3zNR5Nu8jQlseIUfjqusWy\\nHbqq+GPb4y3gJ06Zk/8uolyUHkZJTZe0cvuNZOxNSIBwM6QV3dE4OVx+3SV88GZ/\\nOkAMCUpPRLJux6vJo+l0Qcfe074qjRYPv3XUaGXyHXeOZXmze/lLF6wsEzZmP1A+\\nE9xZmP4ucM3ybrYi3ipRu6YwuR2mRASLy8VFMtcYCvNZGv6ODkjF2xmpucHwX78S\\nzO3mGFES3Hnknjzoif5sJuBewNSztXJcQqKgtSpDhQKBgQDCS6bYj1VR691J5wxA\\n5/fl2MwY4ALIKqW4RtJyNRBZ7+WDAVkq99R6lz+AmQsb6QyiZ/yTZHSUI61Bjn0p\\nd2MD/fpQle7ZOMyR1gKZk5fE5lvmfA5sK+Aax3dRI7xjPBXJYI4hiCMAxgYdhgtI\\nG1C/Nf6O2HoE/W2qLEnLZadpowKBgQC9Tl+/9Eq9Q/DI74CG78U0+s2aRq19vsXZ\\n+wCIUm54TcN9xw4nPKYbT24nTVwTrOu2bxEgDVmuAqtWlKGad16LqZFTZ2aUaEFC\\ni1HL8UKSy5XmNcum8mrKL5+MvwExcQUSmalE3PEQDRjV65QNld0EbQ6JNz74025z\\nm+3ISpIEKwKBgADf5E1fP8wRmrplbtmv8Z64PhryjzCleH9+2h2nfX5aJRdU3zjh\\nSrSOj7uddL5YazUj8LAdKKUuD+6WnJueLPTspL7OHfgeWFVjuDlGv80kGE/OSSZV\\ngDm+ohvcZFGyCIsSgzFFcprjSU3Ct7RIYzGpJY8xDEOPfHninyZqO7mvAoGAIsog\\ndppikd3Ghmbda+7sgwwEdPHAOHeyzJiARI1BmAJShu7p/vP6YtJ6H+broQIKX4CR\\n2R4a+QusiUDPYh/F1EzZVEaQZ32xYJVR9vTjky6u4ZvJTWkHjxipbag8g+WNVRnA\\nLdOcyaJeihG9J7H+6C1Smoz4manhhoWFcWWi5/kCgYEAssgWnlZCygCjEQ/XDVtZ\\nC8/uelJnMHO93U4yF6Xk61gazKYpXpKjNkD3xfxAyQ3zkBkWo7CXg1env8pT9ld1\\nraWCeCmH/w8i0ww3Cmplks5mXIYPrPPuUCEW5D6B8hIyNC1VIoaOlva8+FgJYPIv\\nC5AqN3hBRDOUbophIQmAe5I=\\n-----END PRIVATE KEY-----\\n\",\n",
        "    \"client_email\": \"demand@shopper-reviews-477306.iam.gserviceaccount.com\",\n",
        "    \"client_id\": \"100956109416744224832\",\n",
        "    \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "    \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "    \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "    \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/demand%40shopper-reviews-477306.iam.gserviceaccount.com\"\n",
        "}\n",
        "\n",
        "# Initialize BigQuery\n",
        "credentials = service_account.Credentials.from_service_account_info(BIGQUERY_CREDENTIALS)\n",
        "bq_client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÖ Choose Scraping Mode\n",
        "\n",
        "**3 Options:**\n",
        "\n",
        "1. **Historical** - Scrape ALL reviews (first time run)\n",
        "2. **Incremental** - Scrape reviews after a specific date you enter\n",
        "3. **Auto** - Automatically get reviews after the last scraped date in BigQuery (recommended for daily runs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ask user for scraping mode\n",
        "print(\"üîç SCRAPING MODE\")\n",
        "print(\"=\" * 80)\n",
        "print(\"1. Historical (all reviews)\")\n",
        "print(\"2. Incremental (reviews after a specific date)\")\n",
        "print(\"3. Auto (get latest date from BigQuery)\")\n",
        "\n",
        "mode = input(\"\\nSelect mode (1/2/3): \").strip()\n",
        "\n",
        "cutoff_date = None\n",
        "\n",
        "if mode == \"2\":\n",
        "    date_input = input(\"Enter date (YYYY-MM-DD): \").strip()\n",
        "    cutoff_date = pd.to_datetime(date_input, utc=True)\n",
        "    print(f\"‚úÖ Will scrape reviews AFTER {cutoff_date.date()}\")\n",
        "elif mode == \"3\":\n",
        "    try:\n",
        "        query = f\"\"\"\n",
        "        SELECT MAX(iso_date) as latest_date\n",
        "        FROM `{PROJECT_ID}.{DATASET_ID}.{REVIEWS_TABLE}`\n",
        "        \"\"\"\n",
        "        result = bq_client.query(query).to_dataframe()\n",
        "        latest = result['latest_date'].iloc[0]\n",
        "        if pd.notna(latest):\n",
        "            cutoff_date = pd.to_datetime(latest, utc=True)\n",
        "            print(f\"‚úÖ Found latest review date: {cutoff_date}\")\n",
        "            print(f\"   Will scrape reviews AFTER this date\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No existing reviews found. Running historical scrape.\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Reviews table doesn't exist. Running historical scrape.\")\n",
        "else:\n",
        "    print(\"‚úÖ Running HISTORICAL scrape (all reviews)\")\n",
        "\n",
        "# Auto-detect CID column\n",
        "sample_q = f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{SOURCE_TABLE}` LIMIT 1\"\n",
        "sample = bq_client.query(sample_q).to_dataframe()\n",
        "\n",
        "cid_col = None\n",
        "for col in ['cid', 'dataId', 'data_id']:\n",
        "    if col in sample.columns:\n",
        "        cid_col = col\n",
        "        break\n",
        "\n",
        "if not cid_col:\n",
        "    print(\"‚ùå Error: No CID column found!\")\n",
        "    print(f\"Available columns: {list(sample.columns)}\")\n",
        "    raise Exception(\"CID column not found\")\n",
        "\n",
        "# Fetch locations\n",
        "query = f\"\"\"\n",
        "SELECT \n",
        "    {cid_col} as cid,\n",
        "    title,\n",
        "    rating\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.{SOURCE_TABLE}`\n",
        "WHERE {cid_col} IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "locations_df = bq_client.query(query).to_dataframe()\n",
        "print(f\"\\n‚úÖ Using column: {cid_col}\")\n",
        "print(f\"üìç Found {len(locations_df)} locations to process\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to fetch reviews (with optional date cutoff)\n",
        "def fetch_reviews(cid, cutoff_date=None):\n",
        "    conn = http.client.HTTPSConnection(RAPIDAPI_HOST)\n",
        "    headers = {\n",
        "        \"x-rapidapi-key\": RAPIDAPI_KEY,\n",
        "        \"x-rapidapi-host\": RAPIDAPI_HOST\n",
        "    }\n",
        "    \n",
        "    all_reviews = []\n",
        "    page = 1\n",
        "    stop_scraping = False\n",
        "    \n",
        "    while True:\n",
        "        conn.request(\"GET\", f\"/reviews?cid={cid}&sortBy=newest&gl=us&hl=en&page={page}\", headers=headers)\n",
        "        res = conn.getresponse()\n",
        "        data = res.read()\n",
        "        \n",
        "        if res.status != 200:\n",
        "            break\n",
        "            \n",
        "        json_data = json.loads(data.decode(\"utf-8\"))\n",
        "        reviews = json_data.get(\"reviews\", [])\n",
        "        \n",
        "        if not reviews:\n",
        "            break\n",
        "        \n",
        "        # Check cutoff date if specified\n",
        "        if cutoff_date:\n",
        "            filtered_reviews = []\n",
        "            for r in reviews:\n",
        "                review_date = pd.to_datetime(r.get(\"isoDate\"), errors='coerce', utc=True)\n",
        "                if pd.notna(review_date) and review_date > cutoff_date:\n",
        "                    filtered_reviews.append(r)\n",
        "                else:\n",
        "                    stop_scraping = True\n",
        "                    break\n",
        "            \n",
        "            if filtered_reviews:\n",
        "                all_reviews.extend(filtered_reviews)\n",
        "                print(f\"    Page {page}: {len(filtered_reviews)} new reviews (Total: {len(all_reviews)})\")\n",
        "            \n",
        "            if stop_scraping:\n",
        "                print(f\"    ‚èπÔ∏è Reached cutoff date, stopping\")\n",
        "                break\n",
        "        else:\n",
        "            all_reviews.extend(reviews)\n",
        "            print(f\"    Page {page}: {len(reviews)} reviews (Total: {len(all_reviews)})\")\n",
        "        \n",
        "        page += 1\n",
        "        time.sleep(1)\n",
        "    \n",
        "    conn.close()\n",
        "    return all_reviews\n",
        "\n",
        "# Convert reviews to DataFrame\n",
        "def reviews_to_df(reviews, cid, location_title):\n",
        "    df = pd.DataFrame([{\n",
        "        \"cid\": str(cid),\n",
        "        \"location_title\": location_title,\n",
        "        \"review_id\": r.get(\"id\"),\n",
        "        \"rating\": int(r.get(\"rating\")) if r.get(\"rating\") else None,\n",
        "        \"snippet\": r.get(\"snippet\"),\n",
        "        \"likes\": int(r.get(\"likes\")) if r.get(\"likes\") else 0,\n",
        "        \"date\": r.get(\"date\"),\n",
        "        \"iso_date\": r.get(\"isoDate\"),\n",
        "        \"user_name\": r.get(\"user\", {}).get(\"name\"),\n",
        "        \"user_profile\": r.get(\"user\", {}).get(\"link\"),\n",
        "        \"user_reviews_count\": int(r.get(\"user\", {}).get(\"reviews\")) if r.get(\"user\", {}).get(\"reviews\") else None,\n",
        "        \"scraped_at\": datetime.now(timezone.utc)\n",
        "    } for r in reviews])\n",
        "    df['iso_date'] = pd.to_datetime(df['iso_date'], errors='coerce')\n",
        "    return df\n",
        "\n",
        "print(\"‚úÖ Functions defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create Reviews table\n",
        "table_id = f\"{PROJECT_ID}.{DATASET_ID}.{REVIEWS_TABLE}\"\n",
        "\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"cid\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"location_title\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"review_id\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"rating\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"snippet\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"likes\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"date\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"iso_date\", \"TIMESTAMP\"),\n",
        "    bigquery.SchemaField(\"user_name\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"user_profile\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"user_reviews_count\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"scraped_at\", \"TIMESTAMP\")\n",
        "]\n",
        "\n",
        "try:\n",
        "    bq_client.get_table(table_id)\n",
        "    print(\"‚úÖ Reviews table exists\")\n",
        "except:\n",
        "    table = bigquery.Table(table_id, schema=schema)\n",
        "    bq_client.create_table(table)\n",
        "    print(\"‚úÖ Reviews table created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Process all locations\n",
        "all_reviews = []\n",
        "\n",
        "for idx, row in locations_df.iterrows():\n",
        "    cid = row['cid']\n",
        "    title = row['title']\n",
        "    \n",
        "    print(f\"\\n[{idx+1}/{len(locations_df)}] {title}\")\n",
        "    print(f\"  CID: {cid}\")\n",
        "    \n",
        "    reviews = fetch_reviews(cid, cutoff_date)\n",
        "    \n",
        "    if reviews:\n",
        "        df = reviews_to_df(reviews, cid, title)\n",
        "        all_reviews.append(df)\n",
        "        print(f\"  ‚úÖ Collected: {len(reviews)} reviews\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è No new reviews\")\n",
        "    \n",
        "    time.sleep(2)\n",
        "\n",
        "# Combine and upload\n",
        "if all_reviews:\n",
        "    final_df = pd.concat(all_reviews, ignore_index=True)\n",
        "    \n",
        "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
        "    job = bq_client.load_table_from_dataframe(final_df, table_id, job_config=job_config)\n",
        "    job.result()\n",
        "    \n",
        "    print(f\"\\n\" + \"=\" * 80)\n",
        "    print(f\"‚úÖ SUCCESS!\")\n",
        "    print(f\"üìä Uploaded {len(final_df):,} reviews to BigQuery\")\n",
        "    if cutoff_date:\n",
        "        print(f\"üìÖ Date range: After {cutoff_date.date()}\")\n",
        "    print(\"=\" * 80)\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No new reviews collected\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify results\n",
        "query = f\"SELECT COUNT(*) as total FROM `{table_id}`\"\n",
        "result = bq_client.query(query).to_dataframe()\n",
        "print(f\"Total reviews in BigQuery: {result['total'].iloc[0]:,}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
